{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd686e6",
   "metadata": {},
   "source": [
    "불용어(stopword): 코퍼스에서 큰 의미가 없거나 분석 목적에서 벗어나는 단어들. 정확한 분석을 방해하기 때문에 제거해야 함.   \n",
    "  \n",
    "* NLTK는 기본 불용어 목록 179개를 제공  \n",
    "stopwords.words('english')로 접근할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26208383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semin\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9fdf095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\semin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a02884e7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수: 179\n",
      "{'an', 'more', 'other', 'should', 'when', \"couldn't\", 'wouldn', 'mightn', 'just', 'off', \"she's\", 're', 'ours', 've', 'is', 'having', 'why', 'its', 'do', 'the', 'where', \"wouldn't\", 'few', \"hadn't\", 'me', 'at', 'each', 'have', 'theirs', 'he', \"you'll\", \"you'd\", 'through', \"mightn't\", 'down', 'has', 'now', 'by', 'it', 'herself', 'again', 'all', 'most', 'shan', 'being', \"wasn't\", 'so', \"isn't\", 'if', 'such', 'that', 'his', 'hadn', 'on', 'your', 'here', 'this', 'shouldn', 'about', 'because', 's', \"won't\", 'itself', 'ourselves', 'there', \"mustn't\", 'up', 'them', 'no', 'above', 'does', 'nor', 'until', 'to', 'during', 'did', 'd', 'll', 'didn', 'yourself', 'over', 'as', 'which', 'or', 'hasn', 'for', 'couldn', \"haven't\", \"you're\", 'will', 'in', 'a', \"don't\", 'i', 'doesn', 'myself', 'with', 'hers', 'how', 'isn', 'after', 'their', \"hasn't\", \"doesn't\", 'into', 'only', 'wasn', 'these', 'under', 'own', 'y', \"didn't\", \"needn't\", \"should've\", \"that'll\", 'am', 'both', 'had', 'and', 'been', 'we', 'themselves', 'below', 'her', 'further', 'before', 'm', 'yours', 'what', 'same', 'him', 'were', 'very', 'then', 'are', 'ain', 'she', 'our', \"weren't\", 'haven', 'against', 't', \"you've\", 'who', 'aren', 'while', 'once', 'any', 'from', 'weren', 'you', 'yourselves', 'was', 'those', 'between', 'needn', 'some', 'mustn', 'o', \"shouldn't\", 'my', 'can', 'whom', 'be', 'they', 'won', 'of', 'than', 'but', 'don', \"aren't\", 'himself', 'not', 'out', 'ma', \"shan't\", \"it's\", 'doing', 'too'}\n"
     ]
    }
   ],
   "source": [
    "#받아온 불용어들을 세트 자료형으로 저장\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "print('불용어 개수:', len(stopwords_set))\n",
    "print(stopwords_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d79ac4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수: 178\n",
      "{'an', 'more', 'other', 'should', 'when', \"couldn't\", 'wouldn', 'mightn', 'just', 'off', \"she's\", 're', 'ours', 've', 'is', 'having', 'why', 'its', 'do', 'where', \"wouldn't\", 'few', \"hadn't\", 'at', 'each', 'have', 'theirs', 'he', \"you'll\", \"you'd\", 'through', \"mightn't\", 'down', 'has', 'now', 'by', 'it', 'herself', 'again', 'all', 'most', 'shan', 'being', \"wasn't\", 'so', \"isn't\", 'if', 'such', 'that', 'his', 'hadn', 'on', 'your', 'here', 'this', 'shouldn', 'about', 'because', 's', \"won't\", 'itself', 'ourselves', 'there', \"mustn't\", 'up', 'them', 'no', 'above', 'does', 'nor', 'until', 'to', 'during', 'did', 'd', 'll', 'didn', 'yourself', 'over', 'as', 'which', 'or', 'hasn', 'for', 'couldn', \"haven't\", \"you're\", 'will', 'in', 'a', \"don't\", 'i', 'doesn', 'myself', 'with', 'hers', 'how', 'isn', 'after', 'their', \"hasn't\", \"doesn't\", 'into', 'only', 'wasn', 'these', 'under', 'own', 'y', \"didn't\", \"needn't\", \"should've\", \"that'll\", 'am', 'both', 'had', 'and', 'been', 'we', 'themselves', 'below', 'her', 'further', 'before', 'm', 'hello', 'yours', 'what', 'same', 'him', 'were', 'very', 'then', 'are', 'ain', 'she', 'our', \"weren't\", 'haven', 'against', 't', \"you've\", 'who', 'aren', 'while', 'once', 'any', 'from', 'weren', 'you', 'yourselves', 'was', 'those', 'between', 'needn', 'some', 'mustn', 'o', \"shouldn't\", 'my', 'can', 'whom', 'be', 'they', 'won', 'of', 'than', 'but', 'don', \"aren't\", 'himself', 'not', 'out', 'ma', \"shan't\", \"it's\", 'doing', 'too'}\n"
     ]
    }
   ],
   "source": [
    "#NLTK에서 기본 제공하는 불용어에 새로운 단어를 추가하거나, \n",
    "#일부 단어를 기본 불용어 목록에서 제거해야 할 수도 있음\n",
    "\n",
    "stopwords_set.add('hello')\n",
    "stopwords_set.remove('the')\n",
    "stopwords_set.remove('me')\n",
    "\n",
    "print('불용어 개수:', len(stopwords_set))\n",
    "print(stopwords_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa52d0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'our', 'i', 'ours', 'myself', 'ourselves', 'my', 'we', 'me'}\n"
     ]
    }
   ],
   "source": [
    "#NLTK가 기본 제공하는 불용어가 아니라 \n",
    "#새로운 불용어 세트를 정의해서 사용할 수도 있습니다.\n",
    "\n",
    "my_stopwords_set={'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves'}\n",
    "print(my_stopwords_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d586b43e",
   "metadata": {},
   "source": [
    "# 불용어 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30367a74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_by_freq_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#불용어 제거\u001b[39;00m\n\u001b[0;32m      4\u001b[0m cleaned_words \u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcleaned_by_freq_len\u001b[49m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words_set:\n\u001b[0;32m      7\u001b[0m         cleaned_words\u001b[38;5;241m.\u001b[39mappend(word)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaned_by_freq_len' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words_set = set(stopwords.words('english'))\n",
    "\n",
    "#불용어 제거\n",
    "cleaned_words =[]\n",
    "for word in cleaned_by_freq_len:\n",
    "    if word not in stop_words_set:\n",
    "        cleaned_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ebbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('불용어 제거 전:', len(cleaned_by_freq_len))\n",
    "print('불용어 제거 후:', len(cleaned_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거 함수\n",
    "def clean_by_stopwords(tokenized_words, stop_words_set):\n",
    "    cleaned_words = []\n",
    "    \n",
    "    for word in tokenized_words:\n",
    "        if word not in stop_words_set:\n",
    "            cleaned_words.append(word)\n",
    "            \n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726090f",
   "metadata": {},
   "source": [
    "# 정규화 Normalization\n",
    "의미가 같은 단어이면 형태를 하나로 통일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467fe43",
   "metadata": {},
   "source": [
    "## 방법1 : 대소문자 통합\n",
    "대문자를 소문자로 바꾸기  \n",
    "파이썬의 문자열 내장함수인 lower()가 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13e876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what can i do for you? do your homework now.\n"
     ]
    }
   ],
   "source": [
    "text = \"What can I do for you? Do your homework now.\"\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132bd57",
   "metadata": {},
   "source": [
    "## 방법2 : 규칙 기반 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ee6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동의어 사전\n",
    "synonym_dict = {'US':'USA', 'U.S':'USA', 'Ummm':'Umm', 'Ummmm':'Umm' }\n",
    "\n",
    "text = \"She became a US citizen. Ummmm, I think, maybe and or.\"\n",
    "normalized_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9cb611b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['She',\n",
       " 'became',\n",
       " 'a',\n",
       " 'US',\n",
       " 'citizen',\n",
       " '.',\n",
       " 'Ummmm',\n",
       " ',',\n",
       " 'I',\n",
       " 'think',\n",
       " ',',\n",
       " 'maybe',\n",
       " 'and',\n",
       " 'or',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#단어 토큰화\n",
    "tokenized_words = nltk.word_tokenize(text)\n",
    "tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a286d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in tokenized_words:\n",
    "    if word in synonym_dict.keys():\n",
    "        word = synonym_dict[word] #value에 해당하는 값으로 변환\n",
    "    normalized_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638ca929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['She', 'became', 'a', 'USA', 'citizen', '.', 'Umm', ',', 'I', 'think', ',', 'maybe', 'and', 'or', '.']\n"
     ]
    }
   ],
   "source": [
    "print(normalized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb412bca",
   "metadata": {},
   "source": [
    "# 어간 추출 Stemming\n",
    "특정한 단어의 핵심이 되는 부분을 어간(Stem)  \n",
    "서로 다른 형태의 단어들도 어간 추출을 하면 같은 단어로 통합  \n",
    "어간 추출 알고리즘 중 하나인 포터 스테머 알고리즘(Porter Stemmer Algorithm)의 규칙  \n",
    "단순히 어미만 잘라내는 방식으로 어간을 찾고 있는데요. 그렇기 때문에 사전에 없는 단어가 결과로 나오기도 합니다.\n",
    "\n",
    "alize → al (Formalize → Formal)  \n",
    "ational → ate (Relational -> Relate)  \n",
    "ate → 제거 (Activate -> Activ)  \n",
    "ment → 제거 (Encouragement -> Encourage)\n",
    "  \n",
    "NLTK는 어간 추출을 위한 알고리즘으로 포터 스테머(Porter Stemmer)와 랭커스터 스테머(Lancaster Stemmer)를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71ad0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f58474b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "text = \"You are so lovely. I am loving you now.\"\n",
    "porter_stemmed_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3edeacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 토큰화\n",
    "tokenized_words = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a4ca3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in tokenized_words:\n",
    "    stem = porter_stemmer.stem(word)\n",
    "    porter_stemmed_words.append(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bd239e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 : ['You', 'are', 'so', 'lovely', '.', 'I', 'am', 'loving', 'you', 'now', '.']\n",
      "포터 스테머의 어간 추출 후: ['you', 'are', 'so', 'love', '.', 'i', 'am', 'love', 'you', 'now', '.']\n"
     ]
    }
   ],
   "source": [
    "print('어간 추출 전 :', tokenized_words)\n",
    "print('포터 스테머의 어간 추출 후:', porter_stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baa96cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "lancaster_stemmed_words = []\n",
    "\n",
    "# 랭커스터 스테머의 어간 추출\n",
    "for word in tokenized_words:\n",
    "    stem = lancaster_stemmer.stem(word)\n",
    "    lancaster_stemmed_words.append(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f01f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
